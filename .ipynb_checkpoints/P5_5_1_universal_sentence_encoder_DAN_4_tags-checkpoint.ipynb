{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Post-data-(raw-data)\" data-toc-modified-id=\"Import-Post-data-(raw-data)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Post data (raw data)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set-(raw-data)\" data-toc-modified-id=\"Train-set-(raw-data)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Train set (raw data)</a></span></li><li><span><a href=\"#Val-set-(raw-data)\" data-toc-modified-id=\"Val-set-(raw-data)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Val set (raw data)</a></span></li></ul></li><li><span><a href=\"#Import-Tag-data\" data-toc-modified-id=\"Import-Tag-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Tag data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set-(Tag-data)\" data-toc-modified-id=\"Train-set-(Tag-data)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Train set (Tag data)</a></span></li><li><span><a href=\"#Val-set-(Tag-data)\" data-toc-modified-id=\"Val-set-(Tag-data)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Val set (Tag data)</a></span></li></ul></li><li><span><a href=\"#Dataset-pipeline\" data-toc-modified-id=\"Dataset-pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dataset pipeline</a></span></li><li><span><a href=\"#Train-model-:-universal-sentence-encoder-+-RN-dense\" data-toc-modified-id=\"Train-model-:-universal-sentence-encoder-+-RN-dense-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train model : universal sentence encoder + RN dense</a></span></li><li><span><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set\" data-toc-modified-id=\"Train-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Train set</a></span></li><li><span><a href=\"#Val-set\" data-toc-modified-id=\"Val-set-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Val set</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.backend as K\n",
    "print('Tensorflow version : {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Post data (raw data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103225, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the pickle file\n",
    "picklefile = open('train/X_train_filtre.pkl', 'rb')\n",
    "#unpickle the dataframe\n",
    "df_X_train = pickle5.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()\n",
    "\n",
    "#print the dataframe\n",
    "df_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_small</th>\n",
       "      <th>text_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195918</th>\n",
       "      <td>how to store parts of formdata when theyre on ...</td>\n",
       "      <td>[store, part, formdata, -PRON-, be, separate, ...</td>\n",
       "      <td>[store, part, separate, page, whenever, prepar...</td>\n",
       "      <td>[store, part, -PRON-, be, separate, page, when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495592</th>\n",
       "      <td>which tools should no php web developer live w...</td>\n",
       "      <td>[tool, php, web, developer, live, without, lot...</td>\n",
       "      <td>[tool, php, web, developer, live, without, lot...</td>\n",
       "      <td>[tool, php, web, developer, live, without, lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451531</th>\n",
       "      <td>long strings with newlines i have seen c# code...</td>\n",
       "      <td>[long, string, newline, see, c, code, use, tel...</td>\n",
       "      <td>[long, string, newline, tell, compiler, string...</td>\n",
       "      <td>[long, string, newline, see, c, code, use, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542821</th>\n",
       "      <td>about character pointers in c consider this de...</td>\n",
       "      <td>[character, pointers, c, consider, definitiona...</td>\n",
       "      <td>[character, pointers, consider, point, area, m...</td>\n",
       "      <td>[character, pointers, c, consider, see, point,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549984</th>\n",
       "      <td>how to install pythonrsvg without pythongnome2...</td>\n",
       "      <td>[install, pythonrsvg, without, pythongnome, de...</td>\n",
       "      <td>[install, without, desktop, ubuntu, support, p...</td>\n",
       "      <td>[install, without, desktop, ubuntu, need, supp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      raw  \\\n",
       "195918  how to store parts of formdata when theyre on ...   \n",
       "495592  which tools should no php web developer live w...   \n",
       "451531  long strings with newlines i have seen c# code...   \n",
       "542821  about character pointers in c consider this de...   \n",
       "549984  how to install pythonrsvg without pythongnome2...   \n",
       "\n",
       "                                                     Text  \\\n",
       "195918  [store, part, formdata, -PRON-, be, separate, ...   \n",
       "495592  [tool, php, web, developer, live, without, lot...   \n",
       "451531  [long, string, newline, see, c, code, use, tel...   \n",
       "542821  [character, pointers, c, consider, definitiona...   \n",
       "549984  [install, pythonrsvg, without, pythongnome, de...   \n",
       "\n",
       "                                               text_small  \\\n",
       "195918  [store, part, separate, page, whenever, prepar...   \n",
       "495592  [tool, php, web, developer, live, without, lot...   \n",
       "451531  [long, string, newline, tell, compiler, string...   \n",
       "542821  [character, pointers, consider, point, area, m...   \n",
       "549984  [install, without, desktop, ubuntu, support, p...   \n",
       "\n",
       "                                               text_large  \n",
       "195918  [store, part, -PRON-, be, separate, page, when...  \n",
       "495592  [tool, php, web, developer, live, without, lot...  \n",
       "451531  [long, string, newline, see, c, code, use, tel...  \n",
       "542821  [character, pointers, c, consider, see, point,...  \n",
       "549984  [install, without, desktop, ubuntu, need, supp...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (103225, 1)\n"
     ]
    }
   ],
   "source": [
    "# X dataframe to numpy\n",
    "X_train = df_X_train.drop(columns=['Text', 'text_small', 'text_large']).values  # keep raw post\n",
    "print('X shape : {}'.format(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34477, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the pickle file\n",
    "picklefile = open('val/X_val_filtre.pkl', 'rb')\n",
    "#unpickle the dataframe\n",
    "df_X_val = pickle5.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()\n",
    "\n",
    "#print the dataframe\n",
    "df_X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230075</th>\n",
       "      <td>what type of java cache should be used in case...</td>\n",
       "      <td>[type, java, cache, use, case, data, change, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295941</th>\n",
       "      <td>php  how can i show n 0 t x0b r how can i show...</td>\n",
       "      <td>[php, show, n, x, b, r, show, character, webpage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279171</th>\n",
       "      <td>saving hebrew utf8 to database with php when s...</td>\n",
       "      <td>[saving, hebrew, utf, database, php, saving, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201268</th>\n",
       "      <td>can nlog store the current thread user i am us...</td>\n",
       "      <td>[nlog, store, current, thread, user, use, nlog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403510</th>\n",
       "      <td>how do i add a cgpoint to nsmutablearray i wan...</td>\n",
       "      <td>[add, cgpoint, nsmutablearray, want, store, cg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      raw  \\\n",
       "230075  what type of java cache should be used in case...   \n",
       "295941  php  how can i show n 0 t x0b r how can i show...   \n",
       "279171  saving hebrew utf8 to database with php when s...   \n",
       "201268  can nlog store the current thread user i am us...   \n",
       "403510  how do i add a cgpoint to nsmutablearray i wan...   \n",
       "\n",
       "                                                     Text  \n",
       "230075  [type, java, cache, use, case, data, change, f...  \n",
       "295941  [php, show, n, x, b, r, show, character, webpage]  \n",
       "279171  [saving, hebrew, utf, database, php, saving, h...  \n",
       "201268  [nlog, store, current, thread, user, use, nlog...  \n",
       "403510  [add, cgpoint, nsmutablearray, want, store, cg...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (34477, 1)\n"
     ]
    }
   ],
   "source": [
    "# X dataframe to numpy\n",
    "X_val = df_X_val.drop(columns=['Text']).values  # keep raw post\n",
    "print('X shape : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tag data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set (Tag data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle file\n",
    "picklefile = open('train/Y_train_filtre.pkl', 'rb')\n",
    "#unpickle the dataframe\n",
    "df_Y_train = pickle5.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>tags_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195918</th>\n",
       "      <td>[html, database, forms, cookies]</td>\n",
       "      <td>[html, database, forms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495592</th>\n",
       "      <td>[php, development-environment]</td>\n",
       "      <td>[php]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451531</th>\n",
       "      <td>[c++, string]</td>\n",
       "      <td>[c++, string]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542821</th>\n",
       "      <td>[c, arrays, pointers]</td>\n",
       "      <td>[c, arrays]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549984</th>\n",
       "      <td>[python, librsvg, rsvg]</td>\n",
       "      <td>[python]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tags            tags_filtered\n",
       "195918  [html, database, forms, cookies]  [html, database, forms]\n",
       "495592    [php, development-environment]                    [php]\n",
       "451531                     [c++, string]            [c++, string]\n",
       "542821             [c, arrays, pointers]              [c, arrays]\n",
       "549984           [python, librsvg, rsvg]                 [python]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape : (103225, 100)\n"
     ]
    }
   ],
   "source": [
    "# binarize Y\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_train = mlb.fit_transform(df_Y_train['tags_filtered'])\n",
    "print('Y shape : {}'.format(Y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set (Tag data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle file\n",
    "picklefile = open('val/Y_val_filtre.pkl', 'rb')\n",
    "#unpickle the dataframe\n",
    "df_Y_val = pickle5.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>tags_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230075</th>\n",
       "      <td>[java, performance, multithreading, caching, lru]</td>\n",
       "      <td>[caching, java, performance, multithreading]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295941</th>\n",
       "      <td>[php, hidden-characters]</td>\n",
       "      <td>[php]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279171</th>\n",
       "      <td>[php, mysql, utf-8]</td>\n",
       "      <td>[mysql, php]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201268</th>\n",
       "      <td>[c#, .net, nlog]</td>\n",
       "      <td>[c#, .net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403510</th>\n",
       "      <td>[iphone, objective-c, nsarray, cgpoint]</td>\n",
       "      <td>[iphone, objective-c]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Tags  \\\n",
       "230075  [java, performance, multithreading, caching, lru]   \n",
       "295941                           [php, hidden-characters]   \n",
       "279171                                [php, mysql, utf-8]   \n",
       "201268                                   [c#, .net, nlog]   \n",
       "403510            [iphone, objective-c, nsarray, cgpoint]   \n",
       "\n",
       "                                       tags_filtered  \n",
       "230075  [caching, java, performance, multithreading]  \n",
       "295941                                         [php]  \n",
       "279171                                  [mysql, php]  \n",
       "201268                                    [c#, .net]  \n",
       "403510                         [iphone, objective-c]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape : (34477, 100)\n"
     ]
    }
   ],
   "source": [
    "# binarize Y whith train binarizer\n",
    "Y_val = mlb.fit_transform(df_Y_val['tags_filtered'])\n",
    "print('Y shape : {}'.format(Y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags : 100\n"
     ]
    }
   ],
   "source": [
    "# nombre de tags\n",
    "tags_count = Y_train.shape[1]\n",
    "print('Nombre de tags : {}'.format(tags_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal sentence encoder\n",
    "encoder = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(X, Y, batch_size):\n",
    "    def generator():\n",
    "        example_count = X.shape[0]\n",
    "        for i in range(example_count):\n",
    "            x = tf.reshape((tf.convert_to_tensor(X[i], dtype=tf.string)), (1,))\n",
    "            x = tf.reshape(encoder(x), (512,))  # encode post\n",
    "            y = Y[i, :]\n",
    "            yield x, y\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator,\n",
    "                                             output_types=(\n",
    "                                                 tf.float64, tf.float64),\n",
    "                                             output_shapes=(tf.TensorShape([512, ]),\n",
    "                                                            tf.TensorShape([Y.shape[1], ])))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataset = get_dataset(X_train, Y_train, batch_size)\n",
    "val_dataset = get_dataset(X_val, Y_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(256, 512), dtype=float64, numpy=\n",
      "array([[-0.00398598, -0.06714278,  0.00383451, ...,  0.06920544,\n",
      "         0.02128837, -0.04849395],\n",
      "       [ 0.00999459, -0.05821686,  0.01879022, ..., -0.02598965,\n",
      "        -0.05236601, -0.06074374],\n",
      "       [ 0.05299769, -0.0424128 ,  0.05116303, ...,  0.07500345,\n",
      "         0.01311447,  0.00184043],\n",
      "       ...,\n",
      "       [-0.04255071, -0.00389851, -0.01476747, ...,  0.06234134,\n",
      "        -0.04690759, -0.06022419],\n",
      "       [-0.06327029,  0.00036987,  0.06723199, ...,  0.05274028,\n",
      "         0.04898303,  0.02141742],\n",
      "       [-0.01893879, -0.00063862,  0.00702118, ..., -0.02978746,\n",
      "        -0.03101772, -0.00472722]])>, <tf.Tensor: shape=(256, 100), dtype=float64, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])>)\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataset.take(1):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model : universal sentence encoder + RN dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tags_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 313,956\n",
      "Trainable params: 313,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(512,))\n",
    "\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(tags_count, activation='sigmoid')(x)\n",
    "outputs = x\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='tags_model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              #             loss=[tf.keras.losses.binary_crossentropy],\n",
    "              loss=[f1_loss],\n",
    "              metrics=[tf.keras.metrics.Precision(thresholds=0.5), tf.keras.metrics.Recall(thresholds=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "404/404 [==============================] - 339s 840ms/step - loss: 0.7549 - precision: 0.1270 - recall: 0.5858 - val_loss: 0.6143 - val_precision: 0.4797 - val_recall: 0.6089\n",
      "Epoch 2/5\n",
      "404/404 [==============================] - 334s 827ms/step - loss: 0.5944 - precision: 0.4904 - recall: 0.6243 - val_loss: 0.5649 - val_precision: 0.5162 - val_recall: 0.6344\n",
      "Epoch 3/5\n",
      "404/404 [==============================] - 335s 828ms/step - loss: 0.5617 - precision: 0.5149 - recall: 0.6414 - val_loss: 0.5463 - val_precision: 0.5334 - val_recall: 0.6423\n",
      "Epoch 4/5\n",
      "404/404 [==============================] - 335s 828ms/step - loss: 0.5451 - precision: 0.5275 - recall: 0.6498 - val_loss: 0.5351 - val_precision: 0.5413 - val_recall: 0.6477\n",
      "Epoch 5/5\n",
      "404/404 [==============================] - 335s 830ms/step - loss: 0.5335 - precision: 0.5349 - recall: 0.6571 - val_loss: 0.5279 - val_precision: 0.5482 - val_recall: 0.6506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x184642e8f08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, validation_data=val_dataset,\n",
    "          validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modele\n",
    "model_config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "# save JSON config to disk\n",
    "json_config = model.to_json()\n",
    "with open('PickleData/RN_usencoder2tags_model_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# save weights to disk\n",
    "model.save_weights('PickleData/RN_usencoder2tag_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tags\n",
    "import pickle\n",
    "tags = mlb.classes_\n",
    "with open('PickleData/RN_usencoder2tags_tags', 'wb') as f:\n",
    "    pickle.dump(tags, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags dans le jeu de train :168815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mini\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags prédits :200765\n"
     ]
    }
   ],
   "source": [
    "# predict train\n",
    "print('Nombre de tags dans le jeu de train :{}'.format(sum(sum(Y_train))))\n",
    "y_pred = np.concatenate(np.array([model.predict(data[0]) for data in train_dataset]))\n",
    "# seuillage\n",
    "Y_pred_train = (y_pred > 0.5) * 1\n",
    "print('Nombre de tags prédits :{}'.format(sum(sum(Y_pred_train))))\n",
    "train_score = f1_score(Y_train, Y_pred_train, average='macro')  # seuillage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags dans le jeu de val :56448\n",
      "Nombre de tags prédits :66995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mini\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# predict val\n",
    "print('Nombre de tags dans le jeu de val :{}'.format(sum(sum(Y_val))))\n",
    "y_pred = np.concatenate(np.array([model.predict(data[0]) for data in val_dataset]))\n",
    "# seuillage\n",
    "Y_pred_val = (y_pred > 0.5) * 1\n",
    "print('Nombre de tags prédits :{}'.format(sum(sum(Y_pred_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "csv_path = 'results/univ_sent_encoder'\n",
    "clf_name = 'univ_sent_encoder'\n",
    "train_score_macro = f1_score(Y_train, Y_pred_train, average='macro')\n",
    "val_score_macro = f1_score(Y_val, Y_pred_val, average='macro')\n",
    "train_score_micro = f1_score(Y_train, Y_pred_train, average='micro')\n",
    "val_score_micro = f1_score(Y_val, Y_pred_val, average='micro')\n",
    "train_score_weighted = f1_score(Y_train, Y_pred_train, average='weighted')\n",
    "val_score_weighted = f1_score(Y_val, Y_pred_val, average='weighted')\n",
    "train_score_samples = f1_score(Y_train, Y_pred_train, average='samples')\n",
    "val_score_samples = f1_score(Y_val, Y_pred_val, average='samples')\n",
    "with open(csv_path, 'w') as file:\n",
    "    file.write('{};{};{};{};{};{};{};{};{}'.format(clf_name,\n",
    "                                                   train_score_macro,\n",
    "                                                   val_score_macro,\n",
    "                                                   train_score_micro,\n",
    "                                                   val_score_micro,\n",
    "                                                   train_score_weighted,\n",
    "                                                   val_score_weighted,\n",
    "                                                   train_score_samples,\n",
    "                                                   val_score_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.59      0.40      2619\n",
      "           1       0.56      0.62      0.59       303\n",
      "           2       0.53      0.56      0.55       470\n",
      "           3       0.58      0.58      0.58       333\n",
      "           4       0.96      0.78      0.86       438\n",
      "           5       0.62      0.67      0.64       218\n",
      "           6       0.62      0.65      0.64       346\n",
      "           7       0.37      0.64      0.47       294\n",
      "           8       0.62      0.60      0.61      2253\n",
      "           9       0.84      0.68      0.75       811\n",
      "          10       0.47      0.72      0.56       144\n",
      "          11       0.47      0.48      0.47       802\n",
      "          12       0.47      0.68      0.55      5163\n",
      "          13       0.74      0.63      0.68      1858\n",
      "          14       0.56      0.70      0.62       151\n",
      "          15       0.38      0.51      0.43       337\n",
      "          16       0.22      0.61      0.33       331\n",
      "          17       0.74      0.77      0.76       807\n",
      "          18       0.41      0.55      0.47       172\n",
      "          19       0.28      0.42      0.34       559\n",
      "          20       0.45      0.46      0.46       150\n",
      "          21       0.49      0.60      0.54       267\n",
      "          22       0.96      0.55      0.70       313\n",
      "          23       0.47      0.44      0.45       196\n",
      "          24       0.95      0.77      0.85       427\n",
      "          25       0.83      0.75      0.78       283\n",
      "          26       0.48      0.81      0.60       153\n",
      "          27       0.61      0.62      0.61       180\n",
      "          28       0.31      0.39      0.35       194\n",
      "          29       0.66      0.87      0.75       223\n",
      "          30       0.41      0.46      0.43       182\n",
      "          31       0.19      0.44      0.27       205\n",
      "          32       0.65      0.72      0.68       342\n",
      "          33       0.30      0.44      0.35       216\n",
      "          34       0.71      0.63      0.67       193\n",
      "          35       0.87      0.88      0.87       181\n",
      "          36       0.77      0.75      0.76       186\n",
      "          37       0.45      0.56      0.50      1144\n",
      "          38       0.40      0.38      0.39       190\n",
      "          39       0.40      0.59      0.48       197\n",
      "          40       0.28      0.64      0.39       238\n",
      "          41       0.41      0.54      0.46       142\n",
      "          42       0.35      0.61      0.44       210\n",
      "          43       0.78      0.84      0.81      1594\n",
      "          44       0.80      0.76      0.78      3009\n",
      "          45       0.54      0.78      0.64      2156\n",
      "          46       0.82      0.76      0.79      1761\n",
      "          47       0.76      0.71      0.74       208\n",
      "          48       0.13      0.28      0.18       197\n",
      "          49       0.63      0.69      0.66       396\n",
      "          50       0.46      0.62      0.53       261\n",
      "          51       0.50      0.49      0.50       440\n",
      "          52       0.55      0.57      0.56       287\n",
      "          53       0.77      0.63      0.69       161\n",
      "          54       0.63      0.56      0.59       387\n",
      "          55       0.81      0.74      0.77      1120\n",
      "          56       0.74      0.79      0.76       210\n",
      "          57       0.39      0.61      0.48       753\n",
      "          58       0.35      0.50      0.41       238\n",
      "          59       0.85      0.67      0.75       324\n",
      "          60       0.44      0.48      0.46       188\n",
      "          61       0.33      0.39      0.36       411\n",
      "          62       0.90      0.62      0.73       329\n",
      "          63       0.86      0.73      0.79      2376\n",
      "          64       0.81      0.78      0.80      1492\n",
      "          65       0.90      0.75      0.82       499\n",
      "          66       0.54      0.70      0.61       603\n",
      "          67       0.83      0.76      0.79       786\n",
      "          68       0.45      0.39      0.42       328\n",
      "          69       0.95      0.82      0.88       271\n",
      "          70       0.87      0.70      0.77       282\n",
      "          71       0.55      0.59      0.57       162\n",
      "          72       0.72      0.69      0.71       157\n",
      "          73       0.47      0.67      0.55      1294\n",
      "          74       0.60      0.69      0.65       990\n",
      "          75       0.25      0.59      0.35       328\n",
      "          76       0.15      0.46      0.22       146\n",
      "          77       0.41      0.42      0.42       364\n",
      "          78       0.83      0.81      0.82       290\n",
      "          79       0.61      0.51      0.55       191\n",
      "          80       0.29      0.54      0.38       242\n",
      "          81       0.59      0.82      0.69       272\n",
      "          82       0.24      0.42      0.30       156\n",
      "          83       0.28      0.40      0.33       292\n",
      "          84       0.50      0.56      0.53       208\n",
      "          85       0.45      0.29      0.35       581\n",
      "          86       0.61      0.73      0.67       166\n",
      "          87       0.31      0.58      0.41       173\n",
      "          88       0.22      0.39      0.28       135\n",
      "          89       0.42      0.57      0.49       528\n",
      "          90       0.40      0.50      0.45       438\n",
      "          91       0.93      0.74      0.82       351\n",
      "          92       0.56      0.54      0.55       319\n",
      "          93       0.46      0.37      0.41       265\n",
      "          94       0.36      0.47      0.41       649\n",
      "          95       0.54      0.46      0.50       526\n",
      "          96       0.83      0.71      0.77       753\n",
      "          97       0.26      0.73      0.38       150\n",
      "          98       0.53      0.51      0.52       185\n",
      "          99       0.69      0.68      0.68       649\n",
      "\n",
      "   micro avg       0.55      0.65      0.60     56448\n",
      "   macro avg       0.56      0.61      0.57     56448\n",
      "weighted avg       0.60      0.65      0.61     56448\n",
      " samples avg       0.55      0.68      0.57     56448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mini\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_val, Y_pred_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
