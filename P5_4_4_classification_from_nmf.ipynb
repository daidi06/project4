{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Post-data\" data-toc-modified-id=\"Import-Post-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Post data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set\" data-toc-modified-id=\"Train-set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Train set</a></span></li><li><span><a href=\"#Val-set\" data-toc-modified-id=\"Val-set-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Val set</a></span></li></ul></li><li><span><a href=\"#Import-Tag-data\" data-toc-modified-id=\"Import-Tag-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Tag data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set\" data-toc-modified-id=\"Train-set-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Train set</a></span></li><li><span><a href=\"#Val-set\" data-toc-modified-id=\"Val-set-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Val set</a></span></li></ul></li><li><span><a href=\"#Logistic-regression-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Logistic-regression-multilabels-(one-vs-rest)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic regression multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-Logistic-regression-multilabels\" data-toc-modified-id=\"Evaluation-of-Logistic-regression-multilabels-3\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation of Logistic regression multilabels</a></span></li><li><span><a href=\"#SVM-multilabels-(one-vs-rest)\" data-toc-modified-id=\"SVM-multilabels-(one-vs-rest)-4\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>SVM multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-SVM-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Evaluation-of-SVM-multilabels-(one-vs-rest)-4\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation of SVM multilabels (one vs rest)</a></span></li><li><span><a href=\"#Random-forest-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Random-forest-multilabels-(one-vs-rest)-5\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Random forest multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-Random-forest-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Evaluation-of-Random-forest-multilabels-(one-vs-rest)-5\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluation of Random forest multilabels (one vs rest)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.nmf import Nmf\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Post data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103225, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.read_pickle('PickleData/nmf_features_18.pkl')\n",
    "X_train = df_X_train.drop(columns=['post'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34477, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "lda_model = Nmf.load('model/nmf_model_18')\n",
    "num_topic = 18\n",
    "\n",
    "# load train dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df_X_train['post'].values)\n",
    "\n",
    "# load data\n",
    "df_X_val = pd.read_pickle('val/X_val_filtre.pkl')\n",
    "\n",
    "\n",
    "def get_lda_features(post):\n",
    "    post_bow = dictionary.doc2bow(post)\n",
    "    features = lda_model.get_document_topics(post_bow, minimum_probability=0.)\n",
    "    features = gensim.matutils.sparse2full(features, num_topic)\n",
    "    return features\n",
    "\n",
    "\n",
    "df_features = df_X_val['Text'].apply(func=get_lda_features)\n",
    "X_val = df_features.apply(pd.Series).values\n",
    "\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tag data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103225, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_train = pd.read_pickle('train/Y_train_filtre.pkl')\n",
    "df_Y_train = df_Y_train.drop(columns=['Tags'])\n",
    "df_Y_train = df_Y_train.rename(columns={'tags_filtered': 'tag'})\n",
    "\n",
    "# build dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df_Y_train['tag'])\n",
    "\n",
    "# build bow\n",
    "Y_train = [dictionary.doc2bow(text) for text in df_Y_train['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_train = gensim.matutils.corpus2dense(Y_train, len(dictionary), len(Y_train)).T\n",
    "\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags dans le corpus : 168815.0\n"
     ]
    }
   ],
   "source": [
    "count_tags = sum(sum(Y_train))\n",
    "print('Nombre de tags dans le corpus : {}'.format(count_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34477, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_val = pd.read_pickle('val/Y_val_filtre.pkl')\n",
    "df_Y_val = df_Y_val.drop(columns=['Tags'])\n",
    "df_Y_val = df_Y_val.rename(columns={'tags_filtered': 'tag'})\n",
    "\n",
    "# build bow from train set dictionary\n",
    "Y_val = [dictionary.doc2bow(text) for text in df_Y_val['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_val = gensim.matutils.corpus2dense(Y_val, len(dictionary), len(Y_val)).T\n",
    "\n",
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression multilabels (one vs rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, csv_path=None, clf_name=None):\n",
    "    # prediction\n",
    "    # train\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    # val\n",
    "    Y_pred_val = clf.predict(X_val)\n",
    "    print('Nombre de tags présents : {}'.format(sum(sum(Y_val))))\n",
    "    print('Nombre de tags prédits : {}'.format(sum(sum(Y_pred_val))))\n",
    "    print('---------------------------------------------------------')\n",
    "    print(classification_report(Y_val, Y_pred_val, zero_division=0))\n",
    "    if csv_path and clf_name:\n",
    "        train_score_macro = f1_score(Y_train, Y_pred_train, average='macro')\n",
    "        val_score_macro = f1_score(Y_val, Y_pred_val, average='macro')\n",
    "        train_score_micro = f1_score(Y_train, Y_pred_train, average='micro')\n",
    "        val_score_micro = f1_score(Y_val, Y_pred_val, average='micro')\n",
    "        train_score_weighted = f1_score(\n",
    "            Y_train, Y_pred_train, average='weighted')\n",
    "        val_score_weighted = f1_score(Y_val, Y_pred_val, average='weighted')\n",
    "        train_score_samples = f1_score(\n",
    "            Y_train, Y_pred_train, average='samples')\n",
    "        val_score_samples = f1_score(Y_val, Y_pred_val, average='samples')\n",
    "        with open(csv_path, 'w') as file:\n",
    "            file.write('{};{};{};{};{};{};{};{};{}'.format(clf_name,\n",
    "                                                           train_score_macro,\n",
    "                                                           val_score_macro,\n",
    "                                                           train_score_micro,\n",
    "                                                           val_score_micro,\n",
    "                                                           train_score_weighted,\n",
    "                                                           val_score_weighted,\n",
    "                                                           train_score_samples,\n",
    "                                                           val_score_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample train set\n",
    "# sampling\n",
    "num_samples = 15000\n",
    "X_train_s = X_train.sample(n=num_samples,random_state=1)\n",
    "index_to_keep = X_train_s.index.tolist()\n",
    "df_Y_train_s = df_Y_train.loc[index_to_keep]\n",
    "\n",
    "# build dictionary\n",
    "dictionary_s = gensim.corpora.Dictionary(df_Y_train_s['tag'])\n",
    "\n",
    "# build bow\n",
    "Y_train_s = [dictionary_s.doc2bow(text) for text in df_Y_train_s['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_train_s = gensim.matutils.corpus2dense(Y_train_s, len(dictionary_s), len(Y_train_s)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de determiner les meilleurs paramètres du modèle, nous allons utiliser `GridSearchCV` du module `model_selection` de `scikit-learn`. Nous appliquerons cela à un échantillon de 15000 posts afin de reduire le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__C': 10}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0))\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__C': [0.1, 0.5, 1., 5, 10]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(log_clf,\n",
    "                   param_grid,\n",
    "                   scoring='f1_weighted',\n",
    "                   n_jobs=5,\n",
    "                   verbose = 0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le meilleur paramètre determiner, nous appliquerons la classification à toute la base en considérant le meilleur paramètre déterminé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=10, max_iter=10000,\n",
       "                                                 random_state=0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                             C=10,\n",
    "                                             max_iter=10000,\n",
    "                                             verbose=0))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Logistic regression multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 2888\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       559\n",
      "           1       0.27      0.05      0.09       216\n",
      "           2       0.14      0.00      0.01      1144\n",
      "           3       0.37      0.07      0.12      2376\n",
      "           4       0.00      0.00      0.00      1858\n",
      "           5       0.00      0.00      0.00       364\n",
      "           6       0.00      0.00      0.00       294\n",
      "           7       0.00      0.00      0.00       802\n",
      "           8       0.00      0.00      0.00      1492\n",
      "           9       0.00      0.00      0.00       191\n",
      "          10       0.00      0.00      0.00       292\n",
      "          11       0.00      0.00      0.00       186\n",
      "          12       0.44      0.08      0.14      3009\n",
      "          13       0.00      0.00      0.00       438\n",
      "          14       0.00      0.00      0.00       324\n",
      "          15       0.51      0.19      0.28      1294\n",
      "          16       0.57      0.00      0.01      5163\n",
      "          17       0.00      0.00      0.00       329\n",
      "          18       0.00      0.00      0.00       303\n",
      "          19       0.00      0.00      0.00       346\n",
      "          20       0.00      0.00      0.00       194\n",
      "          21       0.41      0.06      0.10      1594\n",
      "          22       0.00      0.00      0.00       753\n",
      "          23       0.00      0.00      0.00       603\n",
      "          24       0.00      0.00      0.00       786\n",
      "          25       0.00      0.00      0.00      2619\n",
      "          26       0.20      0.03      0.05       351\n",
      "          27       0.00      0.00      0.00       411\n",
      "          28       0.00      0.00      0.00       440\n",
      "          29       0.00      0.00      0.00       157\n",
      "          30       0.23      0.01      0.02      2156\n",
      "          31       0.00      0.00      0.00       438\n",
      "          32       0.50      0.17      0.25       990\n",
      "          33       0.00      0.00      0.00       331\n",
      "          34       0.00      0.00      0.00       151\n",
      "          35       0.00      0.00      0.00       427\n",
      "          36       0.17      0.01      0.01      1761\n",
      "          37       0.41      0.02      0.04      2253\n",
      "          38       0.00      0.00      0.00       180\n",
      "          39       0.00      0.00      0.00       581\n",
      "          40       0.00      0.00      0.00       173\n",
      "          41       0.00      0.00      0.00       135\n",
      "          42       0.00      0.00      0.00       811\n",
      "          43       0.00      0.00      0.00       208\n",
      "          44       0.00      0.00      0.00       499\n",
      "          45       0.21      0.03      0.05       649\n",
      "          46       0.19      0.01      0.02       526\n",
      "          47       0.00      0.00      0.00       190\n",
      "          48       0.19      0.03      0.05       319\n",
      "          49       0.00      0.00      0.00       196\n",
      "          50       0.00      0.00      0.00       328\n",
      "          51       0.00      0.00      0.00       181\n",
      "          52       0.00      0.00      0.00       328\n",
      "          53       0.00      0.00      0.00       242\n",
      "          54       0.00      0.00      0.00       218\n",
      "          55       0.00      0.00      0.00       205\n",
      "          56       0.00      0.00      0.00       287\n",
      "          57       0.00      0.00      0.00       271\n",
      "          58       0.25      0.01      0.02      1120\n",
      "          59       0.00      0.00      0.00       807\n",
      "          60       0.00      0.00      0.00       197\n",
      "          61       0.00      0.00      0.00       238\n",
      "          62       0.00      0.00      0.00       528\n",
      "          63       0.00      0.00      0.00       146\n",
      "          64       0.00      0.00      0.00       210\n",
      "          65       0.00      0.00      0.00       387\n",
      "          66       0.00      0.00      0.00       150\n",
      "          67       0.00      0.00      0.00       267\n",
      "          68       0.00      0.00      0.00       470\n",
      "          69       0.00      0.00      0.00       193\n",
      "          70       0.00      0.00      0.00       753\n",
      "          71       0.00      0.00      0.00       265\n",
      "          72       0.00      0.00      0.00       223\n",
      "          73       0.00      0.00      0.00       156\n",
      "          74       0.00      0.00      0.00       238\n",
      "          75       0.00      0.00      0.00       210\n",
      "          76       0.33      0.00      0.01       396\n",
      "          77       0.25      0.03      0.05       261\n",
      "          78       0.00      0.00      0.00       337\n",
      "          79       0.00      0.00      0.00       333\n",
      "          80       0.00      0.00      0.00       283\n",
      "          81       0.00      0.00      0.00       185\n",
      "          82       0.00      0.00      0.00       290\n",
      "          83       0.00      0.00      0.00       342\n",
      "          84       0.00      0.00      0.00       150\n",
      "          85       0.39      0.15      0.22       272\n",
      "          86       0.00      0.00      0.00       197\n",
      "          87       0.00      0.00      0.00       172\n",
      "          88       0.00      0.00      0.00       142\n",
      "          89       0.00      0.00      0.00       282\n",
      "          90       0.00      0.00      0.00       166\n",
      "          91       0.00      0.00      0.00       182\n",
      "          92       0.00      0.00      0.00       162\n",
      "          93       0.00      0.00      0.00       188\n",
      "          94       0.00      0.00      0.00       208\n",
      "          95       0.00      0.00      0.00       313\n",
      "          96       0.00      0.00      0.00       649\n",
      "          97       0.00      0.00      0.00       161\n",
      "          98       0.00      0.00      0.00       144\n",
      "          99       0.00      0.00      0.00       153\n",
      "\n",
      "   micro avg       0.40      0.02      0.04     56448\n",
      "   macro avg       0.06      0.01      0.02     56448\n",
      "weighted avg       0.17      0.02      0.03     56448\n",
      " samples avg       0.03      0.02      0.02     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/log_reg_nmf.csv', 'Regression logistique nmf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM multilabels (one vs rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "svm_clf = OneVsRestClassifier(LinearSVC(random_state=0,\n",
    "                                        class_weight='balanced',\n",
    "                                        max_iter=10000,\n",
    "                                        verbose=0))\n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__C': [0.1, 0.5, 1., 5, 10]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(svm_clf,\n",
    "                   param_grid,\n",
    "                   scoring='f1_weighted',\n",
    "                   n_jobs=5,\n",
    "                   verbose = 0,\n",
    "                   return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=0.1, class_weight='balanced',\n",
       "                                        max_iter=10000, random_state=0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0,\n",
    "                                    class_weight='balanced',\n",
    "                                    C=0.1,\n",
    "                                    max_iter=10000,\n",
    "                                    verbose=0))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of SVM multilabels (one-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 868704\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.81      0.14       559\n",
      "           1       0.08      0.87      0.14       216\n",
      "           2       0.12      0.79      0.20      1144\n",
      "           3       0.21      0.71      0.33      2376\n",
      "           4       0.11      0.79      0.20      1858\n",
      "           5       0.07      0.82      0.12       364\n",
      "           6       0.03      0.80      0.06       294\n",
      "           7       0.06      0.82      0.10       802\n",
      "           8       0.08      0.69      0.14      1492\n",
      "           9       0.02      0.74      0.03       191\n",
      "          10       0.02      0.77      0.03       292\n",
      "          11       0.02      0.69      0.03       186\n",
      "          12       0.21      0.67      0.32      3009\n",
      "          13       0.03      0.68      0.05       438\n",
      "          14       0.04      0.75      0.07       324\n",
      "          15       0.26      0.87      0.40      1294\n",
      "          16       0.22      0.55      0.31      5163\n",
      "          17       0.02      0.69      0.03       329\n",
      "          18       0.01      0.72      0.03       303\n",
      "          19       0.01      0.77      0.03       346\n",
      "          20       0.04      0.79      0.08       194\n",
      "          21       0.14      0.68      0.24      1594\n",
      "          22       0.05      0.69      0.09       753\n",
      "          23       0.03      0.69      0.06       603\n",
      "          24       0.04      0.70      0.08       786\n",
      "          25       0.12      0.64      0.21      2619\n",
      "          26       0.09      0.85      0.17       351\n",
      "          27       0.02      0.73      0.04       411\n",
      "          28       0.03      0.80      0.05       440\n",
      "          29       0.01      0.64      0.02       157\n",
      "          30       0.18      0.72      0.29      2156\n",
      "          31       0.06      0.73      0.12       438\n",
      "          32       0.23      0.88      0.36       990\n",
      "          33       0.03      0.66      0.05       331\n",
      "          34       0.01      0.81      0.03       151\n",
      "          35       0.02      0.61      0.05       427\n",
      "          36       0.17      0.79      0.28      1761\n",
      "          37       0.16      0.64      0.25      2253\n",
      "          38       0.02      0.74      0.03       180\n",
      "          39       0.02      0.51      0.05       581\n",
      "          40       0.03      0.75      0.05       173\n",
      "          41       0.01      0.63      0.02       135\n",
      "          42       0.06      0.74      0.12       811\n",
      "          43       0.02      0.69      0.04       208\n",
      "          44       0.06      0.82      0.11       499\n",
      "          45       0.08      0.71      0.15       649\n",
      "          46       0.06      0.70      0.11       526\n",
      "          47       0.02      0.77      0.04       190\n",
      "          48       0.07      0.78      0.14       319\n",
      "          49       0.01      0.75      0.03       196\n",
      "          50       0.08      0.91      0.15       328\n",
      "          51       0.02      0.87      0.04       181\n",
      "          52       0.02      0.68      0.04       328\n",
      "          53       0.05      0.86      0.09       242\n",
      "          54       0.02      0.84      0.05       218\n",
      "          55       0.01      0.72      0.02       205\n",
      "          56       0.02      0.70      0.04       287\n",
      "          57       0.02      0.70      0.04       271\n",
      "          58       0.14      0.82      0.24      1120\n",
      "          59       0.10      0.85      0.18       807\n",
      "          60       0.01      0.79      0.02       197\n",
      "          61       0.05      0.81      0.10       238\n",
      "          62       0.09      0.74      0.16       528\n",
      "          63       0.04      0.91      0.07       146\n",
      "          64       0.02      0.73      0.04       210\n",
      "          65       0.05      0.75      0.10       387\n",
      "          66       0.03      0.89      0.05       150\n",
      "          67       0.02      0.70      0.04       267\n",
      "          68       0.04      0.67      0.08       470\n",
      "          69       0.03      0.81      0.06       193\n",
      "          70       0.06      0.80      0.11       753\n",
      "          71       0.03      0.75      0.05       265\n",
      "          72       0.01      0.63      0.03       223\n",
      "          73       0.01      0.77      0.02       156\n",
      "          74       0.02      0.71      0.04       238\n",
      "          75       0.02      0.77      0.04       210\n",
      "          76       0.04      0.83      0.08       396\n",
      "          77       0.05      0.84      0.09       261\n",
      "          78       0.02      0.69      0.03       337\n",
      "          79       0.02      0.79      0.05       333\n",
      "          80       0.03      0.82      0.06       283\n",
      "          81       0.02      0.75      0.03       185\n",
      "          82       0.05      0.88      0.09       290\n",
      "          83       0.02      0.71      0.03       342\n",
      "          84       0.01      0.83      0.02       150\n",
      "          85       0.12      0.89      0.22       272\n",
      "          86       0.03      0.87      0.05       197\n",
      "          87       0.01      0.76      0.03       172\n",
      "          88       0.01      0.75      0.02       142\n",
      "          89       0.02      0.75      0.03       282\n",
      "          90       0.01      0.69      0.02       166\n",
      "          91       0.02      0.73      0.03       182\n",
      "          92       0.03      0.84      0.05       162\n",
      "          93       0.02      0.80      0.03       188\n",
      "          94       0.01      0.75      0.03       208\n",
      "          95       0.01      0.65      0.03       313\n",
      "          96       0.05      0.72      0.10       649\n",
      "          97       0.02      0.80      0.04       161\n",
      "          98       0.01      0.86      0.02       144\n",
      "          99       0.02      0.81      0.03       153\n",
      "\n",
      "   micro avg       0.05      0.72      0.09     56448\n",
      "   macro avg       0.05      0.76      0.09     56448\n",
      "weighted avg       0.11      0.72      0.18     56448\n",
      " samples avg       0.05      0.73      0.09     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/svm_nmf.csv', 'SVM nmf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest multilabels (one vs rest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__max_depth': 10, 'estimator__max_features': 0.75, 'estimator__min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "randf = OneVsRestClassifier(RandomForestClassifier(random_state=0,\n",
    "                                                 n_estimators=50,\n",
    "                                                 max_features=0.75,\n",
    "                                                 min_samples_leaf=1,\n",
    "                                                 max_depth=10,\n",
    "                                                 n_jobs=5,\n",
    "                                                 criterion='gini'))\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = {'estimator__max_features':[0.25, 0.5, 0.75],\n",
    "             'estimator__min_samples_leaf':[1, 3, 10],\n",
    "             'estimator__max_depth':[5, 10]} \n",
    "\n",
    "# cross-validation\n",
    "\n",
    "clf = GridSearchCV(randf,\n",
    "                  param_grid,\n",
    "                  scoring='f1_weighted',\n",
    "                  n_jobs=5,\n",
    "                  verbose = 0,\n",
    "                  return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                     max_features=0.75,\n",
       "                                                     n_estimators=50,\n",
       "                                                     random_state=0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(random_state=0,\n",
    "                                                 max_depth=10,  # 10\n",
    "                                                 min_samples_leaf=1, # 1\n",
    "                                                 max_features=0.75, # 0.75\n",
    "                                                 n_estimators=50,\n",
    "                                                 criterion='gini'))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Random forest multilabels (one-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 8121\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.01      0.02       559\n",
      "           1       1.00      0.00      0.01       216\n",
      "           2       0.46      0.02      0.04      1144\n",
      "           3       0.74      0.28      0.40      2376\n",
      "           4       0.65      0.01      0.02      1858\n",
      "           5       0.00      0.00      0.00       364\n",
      "           6       0.41      0.05      0.09       294\n",
      "           7       0.00      0.00      0.00       802\n",
      "           8       0.68      0.08      0.14      1492\n",
      "           9       0.00      0.00      0.00       191\n",
      "          10       0.00      0.00      0.00       292\n",
      "          11       1.00      0.01      0.01       186\n",
      "          12       0.78      0.38      0.51      3009\n",
      "          13       0.00      0.00      0.00       438\n",
      "          14       0.00      0.00      0.00       324\n",
      "          15       0.57      0.25      0.34      1294\n",
      "          16       0.59      0.02      0.04      5163\n",
      "          17       0.00      0.00      0.00       329\n",
      "          18       0.00      0.00      0.00       303\n",
      "          19       0.00      0.00      0.00       346\n",
      "          20       0.33      0.02      0.04       194\n",
      "          21       0.64      0.12      0.21      1594\n",
      "          22       0.00      0.00      0.00       753\n",
      "          23       0.77      0.04      0.07       603\n",
      "          24       1.00      0.00      0.00       786\n",
      "          25       0.73      0.04      0.07      2619\n",
      "          26       0.64      0.14      0.23       351\n",
      "          27       0.00      0.00      0.00       411\n",
      "          28       0.00      0.00      0.00       440\n",
      "          29       0.00      0.00      0.00       157\n",
      "          30       0.62      0.21      0.32      2156\n",
      "          31       0.42      0.01      0.02       438\n",
      "          32       0.65      0.48      0.55       990\n",
      "          33       0.00      0.00      0.00       331\n",
      "          34       0.67      0.01      0.03       151\n",
      "          35       0.00      0.00      0.00       427\n",
      "          36       0.68      0.31      0.43      1761\n",
      "          37       0.69      0.12      0.21      2253\n",
      "          38       0.83      0.03      0.05       180\n",
      "          39       0.00      0.00      0.00       581\n",
      "          40       0.67      0.01      0.02       173\n",
      "          41       0.00      0.00      0.00       135\n",
      "          42       0.63      0.12      0.21       811\n",
      "          43       0.00      0.00      0.00       208\n",
      "          44       0.38      0.02      0.03       499\n",
      "          45       0.47      0.02      0.04       649\n",
      "          46       0.40      0.04      0.08       526\n",
      "          47       0.00      0.00      0.00       190\n",
      "          48       0.43      0.04      0.07       319\n",
      "          49       0.00      0.00      0.00       196\n",
      "          50       0.50      0.01      0.01       328\n",
      "          51       0.67      0.01      0.02       181\n",
      "          52       0.00      0.00      0.00       328\n",
      "          53       0.00      0.00      0.00       242\n",
      "          54       0.00      0.00      0.00       218\n",
      "          55       0.00      0.00      0.00       205\n",
      "          56       0.44      0.01      0.03       287\n",
      "          57       0.00      0.00      0.00       271\n",
      "          58       0.67      0.14      0.23      1120\n",
      "          59       0.66      0.19      0.29       807\n",
      "          60       0.00      0.00      0.00       197\n",
      "          61       0.00      0.00      0.00       238\n",
      "          62       0.50      0.11      0.18       528\n",
      "          63       0.00      0.00      0.00       146\n",
      "          64       0.00      0.00      0.00       210\n",
      "          65       0.61      0.27      0.38       387\n",
      "          66       0.00      0.00      0.00       150\n",
      "          67       0.00      0.00      0.00       267\n",
      "          68       0.00      0.00      0.00       470\n",
      "          69       0.00      0.00      0.00       193\n",
      "          70       0.58      0.02      0.04       753\n",
      "          71       0.00      0.00      0.00       265\n",
      "          72       0.00      0.00      0.00       223\n",
      "          73       0.00      0.00      0.00       156\n",
      "          74       0.00      0.00      0.00       238\n",
      "          75       1.00      0.00      0.01       210\n",
      "          76       0.63      0.03      0.06       396\n",
      "          77       0.36      0.02      0.03       261\n",
      "          78       0.00      0.00      0.00       337\n",
      "          79       0.00      0.00      0.00       333\n",
      "          80       1.00      0.02      0.04       283\n",
      "          81       1.00      0.01      0.01       185\n",
      "          82       0.46      0.02      0.04       290\n",
      "          83       0.00      0.00      0.00       342\n",
      "          84       0.00      0.00      0.00       150\n",
      "          85       0.64      0.32      0.42       272\n",
      "          86       0.00      0.00      0.00       197\n",
      "          87       0.00      0.00      0.00       172\n",
      "          88       0.00      0.00      0.00       142\n",
      "          89       0.00      0.00      0.00       282\n",
      "          90       0.00      0.00      0.00       166\n",
      "          91       0.75      0.02      0.03       182\n",
      "          92       0.67      0.01      0.02       162\n",
      "          93       0.00      0.00      0.00       188\n",
      "          94       0.00      0.00      0.00       208\n",
      "          95       0.00      0.00      0.00       313\n",
      "          96       0.71      0.14      0.24       649\n",
      "          97       0.71      0.03      0.06       161\n",
      "          98       0.00      0.00      0.00       144\n",
      "          99       0.64      0.05      0.09       153\n",
      "\n",
      "   micro avg       0.67      0.10      0.17     56448\n",
      "   macro avg       0.33      0.04      0.07     56448\n",
      "weighted avg       0.49      0.10      0.14     56448\n",
      " samples avg       0.15      0.11      0.12     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/rand_forest_nmf.csv', 'Random forest nmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
