{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Post-data\" data-toc-modified-id=\"Import-Post-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Post data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set\" data-toc-modified-id=\"Train-set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Train set</a></span></li><li><span><a href=\"#Val-set\" data-toc-modified-id=\"Val-set-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Val set</a></span></li></ul></li><li><span><a href=\"#Import-Tag-data\" data-toc-modified-id=\"Import-Tag-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Tag data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-set\" data-toc-modified-id=\"Train-set-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Train set</a></span></li><li><span><a href=\"#Val-set\" data-toc-modified-id=\"Val-set-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Val set</a></span></li></ul></li><li><span><a href=\"#Logistic-regression-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Logistic-regression-multilabels-(one-vs-rest)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic regression multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-Logistic-regression-multilabels\" data-toc-modified-id=\"Evaluation-of-Logistic-regression-multilabels-3\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation of Logistic regression multilabels</a></span></li><li><span><a href=\"#SVM-multilabels-(one-vs-rest)\" data-toc-modified-id=\"SVM-multilabels-(one-vs-rest)-4\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>SVM multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-SVM-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Evaluation-of-SVM-multilabels-(one-vs-rest)-4\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation of SVM multilabels (one vs rest)</a></span></li><li><span><a href=\"#Random-forest-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Random-forest-multilabels-(one-vs-rest)-5\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Random forest multilabels (one vs rest)</a></span></li><li><span><a href=\"#Evaluation-of-Random-forest-multilabels-(one-vs-rest)\" data-toc-modified-id=\"Evaluation-of-Random-forest-multilabels-(one-vs-rest)-5\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluation of Random forest multilabels (one vs rest)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Post data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103225, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.read_pickle('PickleData/lda_features_12.pkl')\n",
    "X_train = df_X_train.drop(columns=['post'])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34477, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "lda_model = gensim.models.ldamodel.LdaModel.load('model/lda_model_12')\n",
    "num_topic = 12\n",
    "\n",
    "# load train dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df_X_train['post'].values)\n",
    "\n",
    "# load data\n",
    "df_X_val = pd.read_pickle('val/X_val_filtre.pkl')\n",
    "\n",
    "\n",
    "def get_lda_features(post):\n",
    "    post_bow = dictionary.doc2bow(post)\n",
    "    features = lda_model.get_document_topics(post_bow, minimum_probability=0.)\n",
    "    features = gensim.matutils.sparse2full(features, num_topic)\n",
    "    return features\n",
    "\n",
    "\n",
    "df_features = df_X_val['Text'].apply(func=get_lda_features)\n",
    "X_val = df_features.apply(pd.Series).values\n",
    "\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tag data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103225, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_train = pd.read_pickle('train/Y_train_filtre.pkl')\n",
    "df_Y_train = df_Y_train.drop(columns=['Tags'])\n",
    "df_Y_train = df_Y_train.rename(columns={'tags_filtered': 'tag'})\n",
    "\n",
    "# build dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df_Y_train['tag'])\n",
    "\n",
    "# build bow\n",
    "Y_train = [dictionary.doc2bow(text) for text in df_Y_train['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_train = gensim.matutils.corpus2dense(Y_train, len(dictionary), len(Y_train)).T\n",
    "\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags dans le corpus : 168815.0\n"
     ]
    }
   ],
   "source": [
    "count_tags = sum(sum(Y_train))\n",
    "print('Nombre de tags dans le corpus : {}'.format(count_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34477, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_val = pd.read_pickle('val/Y_val_filtre.pkl')\n",
    "df_Y_val = df_Y_val.drop(columns=['Tags'])\n",
    "df_Y_val = df_Y_val.rename(columns={'tags_filtered': 'tag'})\n",
    "\n",
    "# build bow from train set dictionary\n",
    "Y_val = [dictionary.doc2bow(text) for text in df_Y_val['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_val = gensim.matutils.corpus2dense(Y_val, len(dictionary), len(Y_val)).T\n",
    "\n",
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression multilabels (one vs rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, csv_path=None, clf_name=None):\n",
    "    # prediction\n",
    "    # train\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    # val\n",
    "    Y_pred_val = clf.predict(X_val)\n",
    "    print('Nombre de tags présents : {}'.format(sum(sum(Y_val))))\n",
    "    print('Nombre de tags prédits : {}'.format(sum(sum(Y_pred_val))))\n",
    "    print('---------------------------------------------------------')\n",
    "    print(classification_report(Y_val, Y_pred_val, zero_division=0))\n",
    "    if csv_path and clf_name:\n",
    "        train_score_macro = f1_score(Y_train, Y_pred_train, average='macro')\n",
    "        val_score_macro = f1_score(Y_val, Y_pred_val, average='macro')\n",
    "        train_score_micro = f1_score(Y_train, Y_pred_train, average='micro')\n",
    "        val_score_micro = f1_score(Y_val, Y_pred_val, average='micro')\n",
    "        train_score_weighted = f1_score(\n",
    "            Y_train, Y_pred_train, average='weighted')\n",
    "        val_score_weighted = f1_score(Y_val, Y_pred_val, average='weighted')\n",
    "        train_score_samples = f1_score(\n",
    "            Y_train, Y_pred_train, average='samples')\n",
    "        val_score_samples = f1_score(Y_val, Y_pred_val, average='samples')\n",
    "        with open(csv_path, 'w') as file:\n",
    "            file.write('{};{};{};{};{};{};{};{};{}'.format(clf_name,\n",
    "                                                           train_score_macro,\n",
    "                                                           val_score_macro,\n",
    "                                                           train_score_micro,\n",
    "                                                           val_score_micro,\n",
    "                                                           train_score_weighted,\n",
    "                                                           val_score_weighted,\n",
    "                                                           train_score_samples,\n",
    "                                                           val_score_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample train set\n",
    "# sampling\n",
    "num_samples = 15000\n",
    "X_train_s = X_train.sample(n=num_samples,random_state=1)\n",
    "index_to_keep = X_train_s.index.tolist()\n",
    "df_Y_train_s = df_Y_train.loc[index_to_keep]\n",
    "\n",
    "# build dictionary\n",
    "dictionary_s = gensim.corpora.Dictionary(df_Y_train_s['tag'])\n",
    "\n",
    "# build bow\n",
    "Y_train_s = [dictionary_s.doc2bow(text) for text in df_Y_train_s['tag'].values]\n",
    "\n",
    "# sparse to dense\n",
    "Y_train_s = gensim.matutils.corpus2dense(Y_train_s, len(dictionary_s), len(Y_train_s)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de determiner les meilleurs paramètres du modèle, nous allons utiliser `GridSearchCV` du module `model_selection` de `scikit-learn`. Nous appliquerons cela à un échantillon de 15000 posts afin de reduire le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__C': 10}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0))\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__C': [0.1, 0.5, 1., 5, 10]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(log_clf,\n",
    "                   param_grid,\n",
    "                   scoring='f1_weighted',\n",
    "                   n_jobs=5,\n",
    "                   verbose = 0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le meilleur paramètre determiner, nous appliquerons la classification à toute la base en considérant le meilleur paramètre déterminé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=10, max_iter=10000,\n",
       "                                                 random_state=0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                             C=10,\n",
    "                                             max_iter=10000,\n",
    "                                             verbose=0))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Logistic regression multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 2634\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       559\n",
      "           1       0.00      0.00      0.00       216\n",
      "           2       0.00      0.00      0.00      1144\n",
      "           3       0.29      0.00      0.00      2376\n",
      "           4       0.00      0.00      0.00      1858\n",
      "           5       0.00      0.00      0.00       364\n",
      "           6       0.00      0.00      0.00       294\n",
      "           7       0.00      0.00      0.00       802\n",
      "           8       0.00      0.00      0.00      1492\n",
      "           9       0.00      0.00      0.00       191\n",
      "          10       0.00      0.00      0.00       292\n",
      "          11       0.00      0.00      0.00       186\n",
      "          12       0.00      0.00      0.00      3009\n",
      "          13       0.00      0.00      0.00       438\n",
      "          14       0.00      0.00      0.00       324\n",
      "          15       0.49      0.21      0.29      1294\n",
      "          16       0.57      0.00      0.00      5163\n",
      "          17       0.00      0.00      0.00       329\n",
      "          18       0.00      0.00      0.00       303\n",
      "          19       0.00      0.00      0.00       346\n",
      "          20       0.00      0.00      0.00       194\n",
      "          21       0.00      0.00      0.00      1594\n",
      "          22       0.00      0.00      0.00       753\n",
      "          23       0.00      0.00      0.00       603\n",
      "          24       0.00      0.00      0.00       786\n",
      "          25       0.00      0.00      0.00      2619\n",
      "          26       0.28      0.03      0.06       351\n",
      "          27       0.00      0.00      0.00       411\n",
      "          28       0.00      0.00      0.00       440\n",
      "          29       0.00      0.00      0.00       157\n",
      "          30       0.38      0.09      0.15      2156\n",
      "          31       0.00      0.00      0.00       438\n",
      "          32       0.33      0.06      0.11       990\n",
      "          33       0.00      0.00      0.00       331\n",
      "          34       0.00      0.00      0.00       151\n",
      "          35       0.00      0.00      0.00       427\n",
      "          36       0.46      0.14      0.22      1761\n",
      "          37       0.28      0.01      0.03      2253\n",
      "          38       0.00      0.00      0.00       180\n",
      "          39       0.00      0.00      0.00       581\n",
      "          40       0.00      0.00      0.00       173\n",
      "          41       0.00      0.00      0.00       135\n",
      "          42       0.24      0.03      0.05       811\n",
      "          43       0.00      0.00      0.00       208\n",
      "          44       0.42      0.01      0.02       499\n",
      "          45       0.00      0.00      0.00       649\n",
      "          46       0.00      0.00      0.00       526\n",
      "          47       0.00      0.00      0.00       190\n",
      "          48       0.00      0.00      0.00       319\n",
      "          49       0.00      0.00      0.00       196\n",
      "          50       0.00      0.00      0.00       328\n",
      "          51       0.45      0.08      0.14       181\n",
      "          52       0.00      0.00      0.00       328\n",
      "          53       0.00      0.00      0.00       242\n",
      "          54       0.00      0.00      0.00       218\n",
      "          55       0.00      0.00      0.00       205\n",
      "          56       0.00      0.00      0.00       287\n",
      "          57       0.00      0.00      0.00       271\n",
      "          58       0.30      0.08      0.12      1120\n",
      "          59       0.00      0.00      0.00       807\n",
      "          60       0.00      0.00      0.00       197\n",
      "          61       0.00      0.00      0.00       238\n",
      "          62       0.00      0.00      0.00       528\n",
      "          63       0.00      0.00      0.00       146\n",
      "          64       0.00      0.00      0.00       210\n",
      "          65       0.15      0.02      0.04       387\n",
      "          66       0.00      0.00      0.00       150\n",
      "          67       0.00      0.00      0.00       267\n",
      "          68       0.00      0.00      0.00       470\n",
      "          69       0.00      0.00      0.00       193\n",
      "          70       0.31      0.05      0.08       753\n",
      "          71       0.00      0.00      0.00       265\n",
      "          72       0.00      0.00      0.00       223\n",
      "          73       0.00      0.00      0.00       156\n",
      "          74       0.00      0.00      0.00       238\n",
      "          75       0.00      0.00      0.00       210\n",
      "          76       0.00      0.00      0.00       396\n",
      "          77       0.00      0.00      0.00       261\n",
      "          78       0.00      0.00      0.00       337\n",
      "          79       0.00      0.00      0.00       333\n",
      "          80       0.00      0.00      0.00       283\n",
      "          81       0.00      0.00      0.00       185\n",
      "          82       0.26      0.06      0.09       290\n",
      "          83       0.00      0.00      0.00       342\n",
      "          84       0.00      0.00      0.00       150\n",
      "          85       0.00      0.00      0.00       272\n",
      "          86       0.00      0.00      0.00       197\n",
      "          87       0.00      0.00      0.00       172\n",
      "          88       0.00      0.00      0.00       142\n",
      "          89       0.00      0.00      0.00       282\n",
      "          90       0.00      0.00      0.00       166\n",
      "          91       0.00      0.00      0.00       182\n",
      "          92       0.00      0.00      0.00       162\n",
      "          93       0.00      0.00      0.00       188\n",
      "          94       0.00      0.00      0.00       208\n",
      "          95       0.00      0.00      0.00       313\n",
      "          96       0.00      0.00      0.00       649\n",
      "          97       0.00      0.00      0.00       161\n",
      "          98       0.00      0.00      0.00       144\n",
      "          99       0.00      0.00      0.00       153\n",
      "\n",
      "   micro avg       0.39      0.02      0.03     56448\n",
      "   macro avg       0.05      0.01      0.01     56448\n",
      "weighted avg       0.14      0.02      0.03     56448\n",
      " samples avg       0.02      0.02      0.02     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/log_reg_lda.csv', 'Regression logistique lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM multilabels (one vs rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "svm_clf = OneVsRestClassifier(LinearSVC(random_state=0,\n",
    "                                    class_weight='balanced',\n",
    "                                    max_iter=10000,\n",
    "                                    verbose=0))\n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__C': [0.1, 0.5, 1., 5, 10]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(svm_clf,\n",
    "                   param_grid,\n",
    "                   scoring='f1_weighted',\n",
    "                   n_jobs=5,\n",
    "                   verbose = 0,\n",
    "                   return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=0.1, class_weight='balanced',\n",
       "                                        max_iter=50000, random_state=0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0,\n",
    "                                    class_weight='balanced',\n",
    "                                    C=0.1,\n",
    "                                    max_iter=50000,\n",
    "                                    verbose=0))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of SVM multilabels (one-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 747452\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.81      0.15       559\n",
      "           1       0.03      0.78      0.05       216\n",
      "           2       0.12      0.83      0.20      1144\n",
      "           3       0.16      0.68      0.26      2376\n",
      "           4       0.11      0.81      0.20      1858\n",
      "           5       0.05      0.82      0.10       364\n",
      "           6       0.05      0.84      0.10       294\n",
      "           7       0.06      0.79      0.11       802\n",
      "           8       0.08      0.65      0.14      1492\n",
      "           9       0.02      0.70      0.03       191\n",
      "          10       0.03      0.85      0.05       292\n",
      "          11       0.03      0.85      0.05       186\n",
      "          12       0.13      0.70      0.21      3009\n",
      "          13       0.03      0.71      0.06       438\n",
      "          14       0.06      0.81      0.11       324\n",
      "          15       0.25      0.85      0.39      1294\n",
      "          16       0.23      0.61      0.33      5163\n",
      "          17       0.03      0.73      0.05       329\n",
      "          18       0.03      0.70      0.06       303\n",
      "          19       0.04      0.70      0.08       346\n",
      "          20       0.02      0.78      0.05       194\n",
      "          21       0.12      0.66      0.20      1594\n",
      "          22       0.04      0.69      0.07       753\n",
      "          23       0.03      0.72      0.05       603\n",
      "          24       0.05      0.69      0.09       786\n",
      "          25       0.13      0.67      0.21      2619\n",
      "          26       0.09      0.90      0.16       351\n",
      "          27       0.03      0.75      0.06       411\n",
      "          28       0.04      0.81      0.07       440\n",
      "          29       0.01      0.87      0.02       157\n",
      "          30       0.22      0.78      0.34      2156\n",
      "          31       0.05      0.76      0.10       438\n",
      "          32       0.16      0.84      0.27       990\n",
      "          33       0.03      0.65      0.05       331\n",
      "          34       0.03      0.83      0.05       151\n",
      "          35       0.04      0.70      0.07       427\n",
      "          36       0.22      0.86      0.35      1761\n",
      "          37       0.17      0.72      0.28      2253\n",
      "          38       0.03      0.86      0.05       180\n",
      "          39       0.03      0.59      0.06       581\n",
      "          40       0.02      0.88      0.05       173\n",
      "          41       0.01      0.77      0.03       135\n",
      "          42       0.12      0.83      0.21       811\n",
      "          43       0.02      0.79      0.04       208\n",
      "          44       0.09      0.90      0.17       499\n",
      "          45       0.05      0.80      0.09       649\n",
      "          46       0.06      0.71      0.11       526\n",
      "          47       0.02      0.84      0.05       190\n",
      "          48       0.06      0.82      0.11       319\n",
      "          49       0.02      0.83      0.04       196\n",
      "          50       0.06      0.88      0.11       328\n",
      "          51       0.07      0.91      0.13       181\n",
      "          52       0.03      0.79      0.06       328\n",
      "          53       0.05      0.85      0.10       242\n",
      "          54       0.02      0.86      0.04       218\n",
      "          55       0.01      0.65      0.02       205\n",
      "          56       0.03      0.71      0.06       287\n",
      "          57       0.03      0.76      0.05       271\n",
      "          58       0.20      0.81      0.32      1120\n",
      "          59       0.11      0.89      0.20       807\n",
      "          60       0.02      0.81      0.03       197\n",
      "          61       0.04      0.81      0.07       238\n",
      "          62       0.07      0.75      0.13       528\n",
      "          63       0.02      0.90      0.05       146\n",
      "          64       0.04      0.89      0.08       210\n",
      "          65       0.09      0.79      0.17       387\n",
      "          66       0.03      0.91      0.05       150\n",
      "          67       0.03      0.73      0.06       267\n",
      "          68       0.06      0.82      0.11       470\n",
      "          69       0.03      0.85      0.05       193\n",
      "          70       0.12      0.81      0.21       753\n",
      "          71       0.02      0.87      0.04       265\n",
      "          72       0.02      0.77      0.04       223\n",
      "          73       0.01      0.75      0.03       156\n",
      "          74       0.03      0.86      0.05       238\n",
      "          75       0.03      0.87      0.06       210\n",
      "          76       0.05      0.86      0.09       396\n",
      "          77       0.04      0.86      0.07       261\n",
      "          78       0.02      0.72      0.03       337\n",
      "          79       0.03      0.76      0.07       333\n",
      "          80       0.04      0.82      0.08       283\n",
      "          81       0.02      0.74      0.04       185\n",
      "          82       0.09      0.91      0.16       290\n",
      "          83       0.05      0.78      0.10       342\n",
      "          84       0.03      0.87      0.06       150\n",
      "          85       0.04      0.85      0.07       272\n",
      "          86       0.03      0.87      0.06       197\n",
      "          87       0.04      0.84      0.07       172\n",
      "          88       0.02      0.86      0.05       142\n",
      "          89       0.03      0.79      0.06       282\n",
      "          90       0.01      0.70      0.02       166\n",
      "          91       0.02      0.81      0.03       182\n",
      "          92       0.04      0.91      0.07       162\n",
      "          93       0.02      0.84      0.04       188\n",
      "          94       0.03      0.80      0.05       208\n",
      "          95       0.02      0.66      0.03       313\n",
      "          96       0.06      0.76      0.11       649\n",
      "          97       0.02      0.78      0.04       161\n",
      "          98       0.02      0.86      0.03       144\n",
      "          99       0.03      0.85      0.06       153\n",
      "\n",
      "   micro avg       0.06      0.75      0.11     56448\n",
      "   macro avg       0.06      0.79      0.10     56448\n",
      "weighted avg       0.11      0.75      0.18     56448\n",
      " samples avg       0.06      0.76      0.11     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/svm_lda.csv', 'SVM lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest multilabels (one vs rest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "\n",
      "{'estimator__max_depth': 10, 'estimator__max_features': 0.75, 'estimator__min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "randf = OneVsRestClassifier(RandomForestClassifier(random_state=0,\n",
    "                                                   n_estimators=50,\n",
    "                                                   criterion='gini'))\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = {'estimator__max_features':[0.25, 0.5, 0.75],\n",
    "             'estimator__min_samples_leaf':[1, 3, 10],\n",
    "             'estimator__max_depth':[5, 10]}\n",
    "\n",
    "# cross-validation\n",
    "\n",
    "clf = GridSearchCV(randf,\n",
    "                  param_grid,\n",
    "                  scoring='f1_weighted',\n",
    "                  n_jobs=5,\n",
    "                  verbose = 0,\n",
    "                  return_train_score=True)\n",
    "\n",
    "clf.fit(X_train_s, Y_train_s)\n",
    "\n",
    "print('Meilleurs hyper-paramètres :\\n')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                     max_features=0.75,\n",
       "                                                     n_estimators=50,\n",
       "                                                     random_state=0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(random_state=0,\n",
    "                                                 max_depth=10,  # 10\n",
    "                                                 min_samples_leaf=1, # 1\n",
    "                                                 max_features=0.75, # 0.75\n",
    "                                                 n_estimators=50,\n",
    "                                                 criterion='gini'))\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Random forest multilabels (one-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags présents : 56448.0\n",
      "Nombre de tags prédits : 1053\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.01      0.02       559\n",
      "           1       0.00      0.00      0.00       216\n",
      "           2       1.00      0.00      0.00      1144\n",
      "           3       0.44      0.00      0.01      2376\n",
      "           4       0.00      0.00      0.00      1858\n",
      "           5       0.00      0.00      0.00       364\n",
      "           6       0.00      0.00      0.00       294\n",
      "           7       0.00      0.00      0.00       802\n",
      "           8       0.00      0.00      0.00      1492\n",
      "           9       0.00      0.00      0.00       191\n",
      "          10       0.00      0.00      0.00       292\n",
      "          11       0.00      0.00      0.00       186\n",
      "          12       0.00      0.00      0.00      3009\n",
      "          13       0.00      0.00      0.00       438\n",
      "          14       0.00      0.00      0.00       324\n",
      "          15       0.52      0.10      0.17      1294\n",
      "          16       0.44      0.01      0.01      5163\n",
      "          17       0.00      0.00      0.00       329\n",
      "          18       0.00      0.00      0.00       303\n",
      "          19       0.00      0.00      0.00       346\n",
      "          20       0.00      0.00      0.00       194\n",
      "          21       0.00      0.00      0.00      1594\n",
      "          22       0.00      0.00      0.00       753\n",
      "          23       0.00      0.00      0.00       603\n",
      "          24       0.00      0.00      0.00       786\n",
      "          25       0.00      0.00      0.00      2619\n",
      "          26       0.42      0.03      0.05       351\n",
      "          27       0.00      0.00      0.00       411\n",
      "          28       0.00      0.00      0.00       440\n",
      "          29       0.00      0.00      0.00       157\n",
      "          30       0.41      0.02      0.04      2156\n",
      "          31       0.00      0.00      0.00       438\n",
      "          32       0.47      0.02      0.03       990\n",
      "          33       0.00      0.00      0.00       331\n",
      "          34       0.00      0.00      0.00       151\n",
      "          35       0.00      0.00      0.00       427\n",
      "          36       0.53      0.07      0.13      1761\n",
      "          37       0.47      0.01      0.01      2253\n",
      "          38       0.00      0.00      0.00       180\n",
      "          39       0.00      0.00      0.00       581\n",
      "          40       1.00      0.01      0.01       173\n",
      "          41       0.00      0.00      0.00       135\n",
      "          42       0.57      0.01      0.03       811\n",
      "          43       0.00      0.00      0.00       208\n",
      "          44       0.35      0.02      0.03       499\n",
      "          45       0.00      0.00      0.00       649\n",
      "          46       0.00      0.00      0.00       526\n",
      "          47       0.00      0.00      0.00       190\n",
      "          48       0.00      0.00      0.00       319\n",
      "          49       0.00      0.00      0.00       196\n",
      "          50       0.00      0.00      0.00       328\n",
      "          51       0.50      0.08      0.13       181\n",
      "          52       0.00      0.00      0.00       328\n",
      "          53       0.00      0.00      0.00       242\n",
      "          54       0.00      0.00      0.00       218\n",
      "          55       0.00      0.00      0.00       205\n",
      "          56       0.00      0.00      0.00       287\n",
      "          57       0.00      0.00      0.00       271\n",
      "          58       0.50      0.01      0.01      1120\n",
      "          59       0.41      0.02      0.04       807\n",
      "          60       0.00      0.00      0.00       197\n",
      "          61       0.00      0.00      0.00       238\n",
      "          62       0.00      0.00      0.00       528\n",
      "          63       0.00      0.00      0.00       146\n",
      "          64       0.00      0.00      0.00       210\n",
      "          65       0.25      0.01      0.01       387\n",
      "          66       0.00      0.00      0.00       150\n",
      "          67       0.00      0.00      0.00       267\n",
      "          68       0.00      0.00      0.00       470\n",
      "          69       0.00      0.00      0.00       193\n",
      "          70       0.64      0.03      0.05       753\n",
      "          71       0.00      0.00      0.00       265\n",
      "          72       0.00      0.00      0.00       223\n",
      "          73       0.00      0.00      0.00       156\n",
      "          74       0.00      0.00      0.00       238\n",
      "          75       0.50      0.00      0.01       210\n",
      "          76       0.00      0.00      0.00       396\n",
      "          77       0.00      0.00      0.00       261\n",
      "          78       0.00      0.00      0.00       337\n",
      "          79       0.00      0.00      0.00       333\n",
      "          80       0.00      0.00      0.00       283\n",
      "          81       0.00      0.00      0.00       185\n",
      "          82       0.34      0.04      0.07       290\n",
      "          83       0.00      0.00      0.00       342\n",
      "          84       0.00      0.00      0.00       150\n",
      "          85       0.00      0.00      0.00       272\n",
      "          86       0.00      0.00      0.00       197\n",
      "          87       0.50      0.01      0.01       172\n",
      "          88       0.00      0.00      0.00       142\n",
      "          89       0.00      0.00      0.00       282\n",
      "          90       0.00      0.00      0.00       166\n",
      "          91       0.00      0.00      0.00       182\n",
      "          92       0.00      0.00      0.00       162\n",
      "          93       0.00      0.00      0.00       188\n",
      "          94       0.00      0.00      0.00       208\n",
      "          95       0.00      0.00      0.00       313\n",
      "          96       0.50      0.00      0.00       649\n",
      "          97       0.00      0.00      0.00       161\n",
      "          98       0.00      0.00      0.00       144\n",
      "          99       0.00      0.00      0.00       153\n",
      "\n",
      "   micro avg       0.47      0.01      0.02     56448\n",
      "   macro avg       0.11      0.01      0.01     56448\n",
      "weighted avg       0.21      0.01      0.02     56448\n",
      " samples avg       0.01      0.01      0.01     56448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(clf, 'results/rand_forest_lda.csv', 'Random forest lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
